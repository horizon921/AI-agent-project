import streamlit as st
import time
from PIL import Image
from openai import OpenAI
from datetime import datetime
from frontend.core.multimodal import encode_image_to_base64, process_audio_to_text, create_multimodal_message
from backend.utils.feedback_system import feedback_system
import sys
import os
project_root = os.path.dirname(os.path.dirname(
    os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)


def handle_chat_assistant(model, temperature, max_tokens, api_key, base_url):
    """å¤„ç†èŠå¤©åŠ©æ‰‹åŠŸèƒ½"""
    st.header("ğŸ’¬ èŠå¤©åŠ©æ‰‹")
    st.session_state.current_app_mode = "èŠå¤©åŠ©æ‰‹"

    # åˆå§‹åŒ–åé¦ˆç³»ç»Ÿ
    feedback_system.init_session_state()

    # æ·»åŠ è‡ªå®šä¹‰CSS
    st.markdown("""
    <style>
      div[data-testid="stFileUploader"] > label { display: none !important; }
      #file-input, #audio-input { display: none; }

      div[data-testid="stFileUploader"] > div:first-child > div:first-child > div:first-child {
            display: none !important;
        }

        div[data-testid="stFileUploader"]:before {
            content: "æ‹–æ‹½æ–‡ä»¶åˆ°è¿™é‡Œæˆ–ç‚¹å‡»æµè§ˆ";
            display: block;
            text-align: center;
            color: #666;
            font-size: 14px;
            margin-bottom: 10px;
        }

      .upload-btn {
        flex: none; width: 32px; height: 32px;
        margin-left: 8px; margin-right: 8px;
        border-radius: 50%; background: #fff;
        box-shadow: 0 1px 3px rgba(0,0,0,0.2);
        cursor: pointer; display: flex;
        align-items: center; justify-content: center;
        font-size: 18px; transition: transform .2s, box-shadow .2s;
      }
      .upload-btn:hover {
        transform: scale(1.1);
        box-shadow: 0 2px 6px rgba(0,0,0,0.3);
      }
    </style>
    """, unsafe_allow_html=True)

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'pending_files' not in st.session_state:
        st.session_state.pending_files = {'image': None, 'audio': None}

    # ğŸ”¥ æ˜¾ç¤ºèŠå¤©å†å²å¹¶ä¸ºæ¯ä¸ªåŠ©æ‰‹å›å¤æ·»åŠ åé¦ˆè¡¨å•
    for i, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            if isinstance(message["content"], str):
                st.markdown(message["content"])
            else:
                for content_item in message["content"]:
                    if content_item["type"] == "text":
                        st.markdown(content_item["text"])
                    elif content_item["type"] == "image_url":
                        st.image(content_item["image_url"]["url"], width=300)

            # ğŸ”¥ ä¸ºæ¯ä¸ªåŠ©æ‰‹å›å¤æ·»åŠ åé¦ˆè¡¨å•
            if message["role"] == "assistant":
                # ä½¿ç”¨æ¶ˆæ¯ç´¢å¼•å’Œå†…å®¹å“ˆå¸Œåˆ›å»ºå”¯ä¸€ID
                message_content = message["content"] if isinstance(
                    message["content"], str) else str(message["content"])
                message_hash = str(hash(message_content[:100]))
                interaction_id = f"chat_msg_{i}_{message_hash}"

                # æ£€æŸ¥æ˜¯å¦å·²ç»æäº¤è¿‡åé¦ˆ
                feedback_key = f"feedback_{interaction_id}"
                is_submitted = st.session_state.get(
                    feedback_key, {}).get('submitted', False)

                if not is_submitted:
                    with st.expander("ğŸ“ ä¸ºè¿™æ¬¡å›ç­”è¯„åˆ†", expanded=False):
                        feedback_system.show_feedback_form(interaction_id)
                else:
                    st.success("âœ… å·²æäº¤åé¦ˆ")

    # æ–‡ä»¶ä¸Šä¼ å™¨
    with st.container():
        col1, col2 = st.columns(2)

        with col1:
            uploaded_image = st.file_uploader(
                "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶",
                type=['png', 'jpg', 'jpeg', 'gif', 'webp'],
                key=f"img_uploader_{st.session_state.get('upload_counter', 0)}",
                label_visibility="collapsed"
            )

        with col2:
            uploaded_audio = st.file_uploader(
                "é€‰æ‹©éŸ³é¢‘æ–‡ä»¶",
                type=['wav', 'mp3', 'm4a', 'ogg'],
                key=f"audio_uploader_{st.session_state.get('upload_counter', 0)}",
                label_visibility="collapsed"
            )

    # å¤„ç†æ–‡ä»¶ä¸Šä¼ 
    if uploaded_image:
        st.session_state.pending_files['image'] = uploaded_image
        st.success("âœ… å›¾ç‰‡å·²é€‰æ‹©ï¼è¯·è¾“å…¥æ¶ˆæ¯åå‘é€")

    if uploaded_audio:
        st.session_state.pending_files['audio'] = uploaded_audio
        st.success("âœ… éŸ³é¢‘å·²é€‰æ‹©ï¼è¯·è¾“å…¥æ¶ˆæ¯åå‘é€")

    # æ˜¾ç¤ºæ–‡ä»¶é¢„è§ˆ
    if st.session_state.pending_files['image']:
        st.markdown("ğŸ“· **å¾…å‘é€å›¾ç‰‡:**")
        try:
            image = Image.open(st.session_state.pending_files['image'])
            st.image(image, width=200)
        except Exception as e:
            st.error(f"å›¾ç‰‡é¢„è§ˆå¤±è´¥: {str(e)}")

    if st.session_state.pending_files['audio']:
        st.markdown("ğŸ¤ **å¾…å‘é€éŸ³é¢‘:**")
        try:
            st.audio(st.session_state.pending_files['audio'])
        except Exception as e:
            st.error(f"éŸ³é¢‘é¢„è§ˆå¤±è´¥: {str(e)}")

    # èŠå¤©è¾“å…¥æ¡†
    prompt = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")

    # JavaScriptæŒ‰é’®ï¼ˆä¿æŒåŸæœ‰åŠŸèƒ½ï¼‰
    st.markdown("""
    <script>
    (function() {
      function insertButtons() {
        const container = document.querySelector('div[data-testid="stChatInput"]');
        if (!container || container.querySelector('.upload-btn')) return;

        container.insertAdjacentHTML('afterbegin', `
          <label for="file-input"  class="upload-btn" title="ä¸Šä¼ å›¾ç‰‡">ğŸ“·</label>
          <label for="audio-input" class="upload-btn" title="ä¸Šä¼ éŸ³é¢‘">ğŸ¤</label>
          <input type="file" id="file-input"  accept="image/*">
          <input type="file" id="audio-input" accept="audio/*">
        `);
      }

      window.addEventListener('click', e => {
        if (e.target.matches('.upload-btn[title="ä¸Šä¼ å›¾ç‰‡"]'))
          document.getElementById('file-input').click();
        if (e.target.matches('.upload-btn[title="ä¸Šä¼ éŸ³é¢‘"]'))
          document.getElementById('audio-input').click();
      });

      if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', insertButtons);
      } else {
        insertButtons();
      }
      new MutationObserver(insertButtons).observe(document.body, {
        childList: true, subtree: true
      });
    })();
    </script>
    """, unsafe_allow_html=True)

    # å¤„ç†ç”¨æˆ·è¾“å…¥
    if prompt:
        audio_text = None
        image = None

        # å¤„ç†è¯­éŸ³
        if st.session_state.pending_files['audio']:
            with st.spinner("ğŸ¤ æ­£åœ¨è¯†åˆ«è¯­éŸ³..."):
                try:
                    audio_bytes = st.session_state.pending_files['audio'].read(
                    )
                    audio_text = process_audio_to_text(audio_bytes)
                    st.session_state.pending_files['audio'].seek(0)
                except Exception as e:
                    audio_text = f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}"

        # å¤„ç†å›¾ç‰‡
        if st.session_state.pending_files['image']:
            try:
                image = Image.open(st.session_state.pending_files['image'])
                st.session_state.pending_files['image'].seek(0)
            except Exception as e:
                st.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}")
                image = None

        # åˆ›å»ºæ¶ˆæ¯
        user_content = create_multimodal_message(prompt, image, audio_text)
        current_model = "Qwen/Qwen2.5-VL-72B-Instruct" if image else model

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append(
            {"role": "user", "content": user_content})

        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(prompt)
            if audio_text and not audio_text.startswith("è¯­éŸ³è¯†åˆ«å¤±è´¥"):
                st.markdown(f"ğŸ¤ **è¯­éŸ³è¾“å…¥**: {audio_text}")
            if image:
                st.image(image, width=300)

        # æ¸…é™¤æ–‡ä»¶
        st.session_state.pending_files = {'image': None, 'audio': None}
        st.session_state.upload_counter = st.session_state.get(
            'upload_counter', 0) + 1

        # ç”ŸæˆAIå›å¤
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""

            try:
                client = OpenAI(api_key=api_key, base_url=base_url)

                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æä¸æ•™è‚²è¾…å¯¼åŠ©æ‰‹ï¼Œæ“…é•¿å¸®åŠ©ç”¨æˆ·è§£ç­”å­¦æœ¯é—®é¢˜ã€åˆ†æè®ºæ–‡å’Œæä¾›æ•™è‚²æŒ‡å¯¼ã€‚å½“ç”¨æˆ·æä¾›å›¾ç‰‡æ—¶ï¼Œè¯·è¯¦ç»†æè¿°å›¾ç‰‡å†…å®¹å¹¶å›ç­”ç›¸å…³é—®é¢˜ã€‚"}
                ]

                recent_messages = st.session_state.messages[-10:] if len(
                    st.session_state.messages) > 10 else st.session_state.messages

                for msg in recent_messages:
                    messages.append(
                        {"role": msg["role"], "content": msg["content"]})

                response = client.chat.completions.create(
                    model=current_model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    stream=True
                )

                for chunk in response:
                    if chunk.choices[0].delta.content is not None:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        message_placeholder.markdown(full_response + "â–Œ")
                        time.sleep(0.01)

                message_placeholder.markdown(full_response)

            except Exception as e:
                error_message = f"APIè°ƒç”¨å‡ºé”™: {str(e)}"
                message_placeholder.error(error_message)
                full_response = error_message

            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
            st.session_state.messages.append(
                {"role": "assistant", "content": full_response})

        # ğŸ”¥ ä¸ºæœ€æ–°å›å¤æ·»åŠ åé¦ˆè¡¨å•
        if full_response and not full_response.startswith("APIè°ƒç”¨å‡ºé”™"):
            # ä¸ºæœ€æ–°çš„å›å¤åˆ›å»ºåé¦ˆè¡¨å•
            latest_msg_index = len(st.session_state.messages) - 1
            message_hash = str(hash(full_response[:100]))
            new_interaction_id = f"chat_msg_{latest_msg_index}_{message_hash}"

            st.markdown("---")

            # ğŸ”¥ ä½¿ç”¨å®¹å™¨æ¥ç¡®ä¿ç¨³å®šæ˜¾ç¤º
            with st.container():
                feedback_system.show_feedback_form(new_interaction_id)
