from duckduckgo_search import DDGS
import streamlit as st
import requests
import json
import time
import base64
from PIL import Image
import io
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from openai import OpenAI
import numpy as np
import math
from scipy import stats, optimize, integrate
import speech_recognition as sr
import tempfile
import os
import re
from typing import Dict, Any, Optional
from datetime import datetime
# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Chat-AI",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

hide_default_format = """
<style>
#MainMenu {visibility: hidden; }
footer {visibility: hidden;}
header {visibility: hidden;}
.stDeployButton {display:none;}
</style>
"""
st.markdown(hide_default_format, unsafe_allow_html=True)

# APIç«¯ç‚¹
API_BASE_URL = "http://localhost:8000/api"

# è®¾ç½®æ ‡é¢˜
st.title("ğŸ“š Chat-AI")


def create_structured_prompt(content: str, task_type: str) -> str:
    """åˆ›å»ºç»“æ„åŒ–æç¤ºè¯"""
    if task_type == "paper_analysis":
        return f"""
è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼åˆ†æè®ºæ–‡ï¼š
{{
    "summary": "è®ºæ–‡æ‘˜è¦æ€»ç»“",
    "main_contributions": ["è´¡çŒ®1", "è´¡çŒ®2", "è´¡çŒ®3"],
    "methodology": "ç ”ç©¶æ–¹æ³•æè¿°",
    "key_findings": ["å‘ç°1", "å‘ç°2", "å‘ç°3"],
    "limitations": ["å±€é™1", "å±€é™2"],
    "significance": "ç ”ç©¶æ„ä¹‰"
}}

é‡è¦ï¼šå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ã€‚

è®ºæ–‡å†…å®¹ï¼š{content}
"""

    elif task_type == "education_content":
        return f"""
è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼ç”Ÿæˆæ•™è‚²å†…å®¹ï¼š
{{
    "concept_explanation": "æ¦‚å¿µè§£é‡Š",
    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"],
    "examples": ["ç¤ºä¾‹1", "ç¤ºä¾‹2", "ç¤ºä¾‹3"],
    "exercises": [
        {{"question": "é—®é¢˜", "answer": "ç­”æ¡ˆ", "difficulty": "åŸºç¡€/ä¸­çº§/é«˜çº§"}}
    ],
    "further_reading": ["æ¨è1", "æ¨è2"]
}}

é‡è¦ï¼šå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ã€‚

ç”Ÿæˆå†…å®¹ï¼š{content}
"""

    return content


def parse_json_response(response: str):
    """å°è¯•è§£æJSONå“åº”"""
    try:
        import re
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
        return None
    except:
        return None


# å¤šæ¨¡æ€å¤„ç†å‡½æ•°


def encode_image_to_base64(image):
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"


def process_audio_to_text(audio_bytes):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_bytes)
            tmp_file_path = tmp_file.name

        recognizer = sr.Recognizer()

        try:
            with sr.AudioFile(tmp_file_path) as source:
                audio = recognizer.record(source)
                text = recognizer.recognize_google(audio, language='zh-CN')
        except:
            try:
                with sr.AudioFile(tmp_file_path) as source:
                    recognizer.adjust_for_ambient_noise(source)
                    audio = recognizer.record(source)
                    text = recognizer.recognize_google(audio, language='zh-CN')
            except Exception as e:
                raise e

        os.unlink(tmp_file_path)
        return text
    except Exception as e:
        return f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}"


def create_multimodal_message(text, image=None, audio_text=None):
    content = []

    if text:
        content.append({"type": "text", "text": text})

    if audio_text and not audio_text.startswith("è¯­éŸ³è¯†åˆ«å¤±è´¥"):
        content.append({"type": "text", "text": f"[è¯­éŸ³è¾“å…¥]: {audio_text}"})

    if image:
        image_base64 = encode_image_to_base64(image)
        content.append({
            "type": "image_url",
            "image_url": {"url": image_base64}
        })

    return content if len(content) > 0 else [{"type": "text", "text": ""}]


# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("æ¨¡å‹è®¾ç½®")

    # ä½¿ç”¨ç”¨æˆ·å‹å¥½çš„æ˜¾ç¤ºåç§°
    model_display = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        ["DeepSeek-V3", "Qwen-72B", "DeepSeek-R1"]
    )

    # æ¨¡å‹åç§°æ˜ å°„ - å°†æ˜¾ç¤ºåç§°æ˜ å°„åˆ°APIä½¿ç”¨çš„å®é™…åç§°
    model_mapping = {
        "DeepSeek-V3": "Pro/deepseek-ai/DeepSeek-V3",
        "Qwen-72B": "Qwen/Qwen2.5-72B-Instruct",
        "DeepSeek-R1": "Pro/deepseek-ai/DeepSeek-R1"
    }

    # è·å–APIä½¿ç”¨çš„å®é™…æ¨¡å‹åç§°
    model = model_mapping.get(model_display, "deepseek-chat")

    temperature = st.slider(
        "Temperature",
        min_value=0.0,
        max_value=2.0,
        value=0.7,
        step=0.1,
        help="å€¼è¶Šé«˜ï¼Œå›ç­”è¶Šå¤šæ ·åŒ–ï¼›å€¼è¶Šä½ï¼Œå›ç­”è¶Šç¡®å®šæ€§"
    )

    max_tokens = st.slider(
        "æœ€å¤§ç”Ÿæˆé•¿åº¦",
        min_value=100,
        max_value=4000,
        value=1000,
        step=100,
        help="æ§åˆ¶å›ç­”çš„æœ€å¤§é•¿åº¦"
    )

    st.divider()

    # åŠŸèƒ½é€‰æ‹©
    st.header("åŠŸèƒ½é€‰æ‹©")
    app_mode = st.radio(
        "é€‰æ‹©åŠŸèƒ½",
        ["èŠå¤©åŠ©æ‰‹", "è®ºæ–‡åˆ†æ", "æ•™è‚²å†…å®¹ç”Ÿæˆ", "å·¥å…·é›†æˆ"]
    )

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

if "code_output" not in st.session_state:
    st.session_state.code_output = None

# åŠŸèƒ½å®ç°
if app_mode == "èŠå¤©åŠ©æ‰‹":
    st.header("ğŸ’¬ èŠå¤©åŠ©æ‰‹")

    # æ·»åŠ è‡ªå®šä¹‰CSS
    st.markdown("""
    <style>
      /* éšè— Streamlit é»˜è®¤ä¸Šä¼ æ§ä»¶ */
      div[data-testid="stFileUploader"] > lable { display: none !important; }

      /* éšè—æˆ‘ä»¬å°†æ’å…¥çš„åŸç”Ÿ input[type=file] */
      #file-input, #audio-input {
        display: none;
      }
      /* éšè—è‹±æ–‡æç¤ºæ–‡å­— */
      div[data-testid="stFileUploader"] > div:first-child > div:first-child > div:first-child {
            display: none !important;
        }

        /* è‡ªå®šä¹‰ä¸­æ–‡æç¤º */
        div[data-testid="stFileUploader"]:before {
            content: "æ‹–æ‹½æ–‡ä»¶åˆ°è¿™é‡Œæˆ–ç‚¹å‡»æµè§ˆ";
            display: block;
            text-align: center;
            color: #666;
            font-size: 14px;
            margin-bottom: 10px;
        }
      /* ä¸Šä¼ å›¾æ ‡æŒ‰é’® */
      .upload-btn {
        flex: none;
        width: 32px;
        height: 32px;
        margin-left: 8px;
        margin-right: 8px;
        border-radius: 50%;
        background: #fff;
        box-shadow: 0 1px 3px rgba(0,0,0,0.2);
        cursor: pointer;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 18px;
        transition: transform .2s, box-shadow .2s;
      }
      .upload-btn:hover {
        transform: scale(1.1);
        box-shadow: 0 2px 6px rgba(0,0,0,0.3);
      }

    </style>
    """, unsafe_allow_html=True)

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'uploaded_image' not in st.session_state:
        st.session_state.uploaded_image = None
    if 'uploaded_audio' not in st.session_state:
        st.session_state.uploaded_audio = None
    if 'pending_files' not in st.session_state:
        st.session_state.pending_files = {'image': None, 'audio': None}

    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if isinstance(message["content"], str):
                st.markdown(message["content"])
            else:
                for content_item in message["content"]:
                    if content_item["type"] == "text":
                        st.markdown(content_item["text"])
                    elif content_item["type"] == "image_url":
                        st.image(content_item["image_url"]["url"], width=300)

    # åˆ›å»ºéšè—çš„æ–‡ä»¶ä¸Šä¼ å™¨ï¼Œä½¿ç”¨å”¯ä¸€çš„key
    with st.container():
        uploaded_image = st.file_uploader(
            "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶",
            type=['png', 'jpg', 'jpeg', 'gif', 'webp'],
            key=f"img_uploader_{st.session_state.get('upload_counter', 0)}",
            label_visibility="collapsed"
        )

        uploaded_audio = st.file_uploader(
            "é€‰æ‹©éŸ³é¢‘æ–‡ä»¶",
            type=['wav', 'mp3', 'm4a', 'ogg'],
            key=f"audio_uploader_{st.session_state.get('upload_counter', 0)}",
            label_visibility="collapsed"
        )

    # å¤„ç†æ–‡ä»¶ä¸Šä¼ 
    if uploaded_image:
        st.session_state.pending_files['image'] = uploaded_image
        st.success("âœ… å›¾ç‰‡å·²é€‰æ‹©ï¼è¯·è¾“å…¥æ¶ˆæ¯åå‘é€")

    if uploaded_audio:
        st.session_state.pending_files['audio'] = uploaded_audio
        st.success("âœ… éŸ³é¢‘å·²é€‰æ‹©ï¼è¯·è¾“å…¥æ¶ˆæ¯åå‘é€")

    # æ˜¾ç¤ºå¾…å‘é€çš„æ–‡ä»¶é¢„è§ˆ
    if st.session_state.pending_files['image']:
        with st.container():
            st.markdown('<div class="file-preview">', unsafe_allow_html=True)
            st.markdown("ğŸ“· **å¾…å‘é€å›¾ç‰‡:**")
            try:
                image = Image.open(st.session_state.pending_files['image'])
                st.image(image, width=200)
            except Exception as e:
                st.error(f"å›¾ç‰‡é¢„è§ˆå¤±è´¥: {str(e)}")
            st.markdown('</div>', unsafe_allow_html=True)

    if st.session_state.pending_files['audio']:
        with st.container():
            st.markdown('<div class="file-preview">', unsafe_allow_html=True)
            st.markdown("ğŸ¤ **å¾…å‘é€éŸ³é¢‘:**")
            try:
                st.audio(st.session_state.pending_files['audio'])
            except Exception as e:
                st.error(f"éŸ³é¢‘é¢„è§ˆå¤±è´¥: {str(e)}")
            st.markdown('</div>', unsafe_allow_html=True)

    # èŠå¤©è¾“å…¥æ¡†
    prompt = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")

    # æ·»åŠ JavaScriptæ¥åˆ›å»ºæŒ‰é’®å¹¶ç»‘å®šç‚¹å‡»äº‹ä»¶
    st.markdown("""
    <script>
    (function() {
      // æ¯æ¬¡æ¸²æŸ“åå°è¯•å¾€è¾“å…¥æ¡†é‡Œæ’å…¥æŒ‰é’®
      function insertButtons() {
        const container = document.querySelector('div[data-testid="stChatInput"]');
        if (!container || container.querySelector('.upload-btn')) return;

        // åœ¨è¾“å…¥æ¡†æœ€å·¦ä¾§æ’å…¥ä¸¤å¯¹ <label> + éšè— <input>
        container.insertAdjacentHTML('afterbegin', `
          <label for="file-input"  class="upload-btn" title="ä¸Šä¼ å›¾ç‰‡">ğŸ“·</label>
          <label for="audio-input" class="upload-btn" title="ä¸Šä¼ éŸ³é¢‘">ğŸ¤</label>
          <input type="file" id="file-input"  accept="image/*">
          <input type="file" id="audio-input" accept="audio/*">
        `);
      }

      // è§¦å‘é€‰æ‹©ï¼šå›¾ç‰‡/éŸ³é¢‘
      window.addEventListener('click', e => {
        if (e.target.matches('.upload-btn[title="ä¸Šä¼ å›¾ç‰‡"]'))
          document.getElementById('file-input').click();
        if (e.target.matches('.upload-btn[title="ä¸Šä¼ éŸ³é¢‘"]'))
          document.getElementById('audio-input').click();
      });

      // åˆæ¬¡æ’å…¥ & ç›‘å¬å¼‚æ­¥æ¸²æŸ“
      if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', insertButtons);
      } else {
        insertButtons();
      }
      new MutationObserver(insertButtons).observe(document.body, {
        childList: true, subtree: true
      });
    })();
    </script>
    """, unsafe_allow_html=True)

    # å¤„ç†ç”¨æˆ·è¾“å…¥
    if prompt:
        audio_text = None
        image = None

        # å¤„ç†å¾…å‘é€çš„è¯­éŸ³
        if st.session_state.pending_files['audio']:
            with st.spinner("ğŸ¤ æ­£åœ¨è¯†åˆ«è¯­éŸ³..."):
                try:
                    audio_bytes = st.session_state.pending_files['audio'].read(
                    )
                    audio_text = process_audio_to_text(audio_bytes)
                    st.session_state.pending_files['audio'].seek(0)
                except Exception as e:
                    audio_text = f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}"

        # å¤„ç†å¾…å‘é€çš„å›¾ç‰‡
        if st.session_state.pending_files['image']:
            try:
                image = Image.open(st.session_state.pending_files['image'])
                st.session_state.pending_files['image'].seek(0)
            except Exception as e:
                st.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}")
                image = None

        # åˆ›å»ºå¤šæ¨¡æ€æ¶ˆæ¯
        user_content = create_multimodal_message(prompt, image, audio_text)

        # é€‰æ‹©æ¨¡å‹
        if image:
            current_model = "Qwen/Qwen2.5-VL-72B-Instruct"
        else:
            current_model = model

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append(
            {"role": "user", "content": user_content})

        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(prompt)
            if audio_text and not audio_text.startswith("è¯­éŸ³è¯†åˆ«å¤±è´¥"):
                st.markdown(f"ğŸ¤ **è¯­éŸ³è¾“å…¥**: {audio_text}")
            if image:
                st.image(image, width=300)

        # æ¸…é™¤å¾…å‘é€çš„æ–‡ä»¶å¹¶æ›´æ–°è®¡æ•°å™¨
        st.session_state.pending_files = {'image': None, 'audio': None}
        st.session_state.upload_counter = st.session_state.get(
            'upload_counter', 0) + 1

        # ç”ŸæˆAIå›å¤
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""

            try:
                client = OpenAI(
                    api_key="sk-qseennfhdprismchczwnkzpohyjmuwgpiaywuclsisgugfvo",
                    base_url="https://api.siliconflow.cn/v1"
                )

                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æä¸æ•™è‚²è¾…å¯¼åŠ©æ‰‹ï¼Œæ“…é•¿å¸®åŠ©ç”¨æˆ·è§£ç­”å­¦æœ¯é—®é¢˜ã€åˆ†æè®ºæ–‡å’Œæä¾›æ•™è‚²æŒ‡å¯¼ã€‚å½“ç”¨æˆ·æä¾›å›¾ç‰‡æ—¶ï¼Œè¯·è¯¦ç»†æè¿°å›¾ç‰‡å†…å®¹å¹¶å›ç­”ç›¸å…³é—®é¢˜ã€‚"}
                ]

                recent_messages = st.session_state.messages[-10:] if len(
                    st.session_state.messages) > 10 else st.session_state.messages

                for msg in recent_messages:
                    messages.append(
                        {"role": msg["role"], "content": msg["content"]})

                response = client.chat.completions.create(
                    model=current_model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    stream=True
                )

                for chunk in response:
                    if chunk.choices[0].delta.content is not None:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        message_placeholder.markdown(full_response + "â–Œ")
                        time.sleep(0.01)

                message_placeholder.markdown(full_response)

            except Exception as e:
                error_message = f"APIè°ƒç”¨å‡ºé”™: {str(e)}"
                message_placeholder.error(error_message)
                full_response = error_message

            st.session_state.messages.append(
                {"role": "assistant", "content": full_response})

        st.rerun()


elif app_mode == "è®ºæ–‡åˆ†æ":
    st.header("ğŸ“ è®ºæ–‡åˆ†æ")

    paper_text = st.text_area(
        "è¯·è¾“å…¥è®ºæ–‡æ–‡æœ¬æˆ–æ‘˜è¦",
        height=300,
        help="ç²˜è´´è®ºæ–‡æ–‡æœ¬ã€æ‘˜è¦æˆ–PDFæå–çš„å†…å®¹"
    )

    col1, col2 = st.columns([1, 3])

    with col1:
        analyze_button = st.button("åˆ†æè®ºæ–‡", type="primary")

    if analyze_button and paper_text:
        with st.spinner("æ­£åœ¨åˆ†æè®ºæ–‡..."):
            try:
                client = OpenAI(
                    api_key="sk-qseennfhdprismchczwnkzpohyjmuwgpiaywuclsisgugfvo",
                    base_url="https://api.siliconflow.cn/v1"
                )

                # ä½¿ç”¨ç»“æ„åŒ–æç¤º
                structured_prompt = create_structured_prompt(
                    paper_text, "paper_analysis")

                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æåŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœã€‚"},
                        {"role": "user", "content": structured_prompt}
                    ],
                    temperature=0.1,  # é™ä½éšæœºæ€§ç¡®ä¿æ ¼å¼ç¨³å®š
                    max_tokens=max_tokens
                )

                analysis_result = response.choices[0].message.content

                # å°è¯•è§£æJSONå¹¶ç¾åŒ–æ˜¾ç¤º
                parsed_data = parse_json_response(analysis_result)

                if parsed_data:
                    # ç»“æ„åŒ–æ˜¾ç¤º
                    st.markdown("### ğŸ“Š è®ºæ–‡åˆ†æç»“æœ")

                    st.markdown("### ğŸ“ æ‘˜è¦æ€»ç»“")
                    st.markdown(parsed_data.get('summary', 'æœªæä¾›æ‘˜è¦'))

                    st.markdown("### ğŸ¯ ä¸»è¦è´¡çŒ®")
                    for i, contrib in enumerate(parsed_data.get('main_contributions', []), 1):
                        st.markdown(f"{i}. {contrib}")

                    st.markdown("### ğŸ”¬ ç ”ç©¶æ–¹æ³•")
                    st.markdown(parsed_data.get('methodology', 'æœªæè¿°'))

                    st.markdown("### ğŸ” å…³é”®å‘ç°")
                    for i, finding in enumerate(parsed_data.get('key_findings', []), 1):
                        st.markdown(f"{i}. {finding}")

                    st.markdown("### âš ï¸ ç ”ç©¶å±€é™")
                    for i, limitation in enumerate(parsed_data.get('limitations', []), 1):
                        st.markdown(f"{i}. {limitation}")

                    st.markdown("### ğŸ’¡ ç ”ç©¶æ„ä¹‰")
                    st.markdown(parsed_data.get('significance', 'æœªè¯„ä¼°'))

                else:
                    # å¦‚æœJSONè§£æå¤±è´¥ï¼Œç›´æ¥æ˜¾ç¤ºåŸå§‹å›å¤
                    st.markdown(analysis_result)

            except Exception as e:
                st.error(f"APIè°ƒç”¨å‡ºé”™: {str(e)}")

elif app_mode == "æ•™è‚²å†…å®¹ç”Ÿæˆ":
    st.header("ğŸ“ æ•™è‚²å†…å®¹ç”Ÿæˆ")

    col1, col2 = st.columns(2)

    with col1:
        topic = st.text_input("è¯·è¾“å…¥ä¸»é¢˜", placeholder="ä¾‹å¦‚ï¼šå…‰åˆä½œç”¨ã€å¾®ç§¯åˆ†ã€äººå·¥æ™ºèƒ½...")

    with col2:
        level = st.selectbox(
            "é€‰æ‹©æ•™è‚²çº§åˆ«",
            ["å°å­¦", "åˆä¸­", "é«˜ä¸­", "å¤§å­¦", "ç ”ç©¶ç”Ÿ"]
        )

    generate_button = st.button("ç”Ÿæˆæ•™è‚²å†…å®¹", type="primary")

    if generate_button and topic:
        with st.spinner(f"æ­£åœ¨ç”Ÿæˆå…³äºã€Œ{topic}ã€çš„{level}çº§åˆ«æ•™è‚²å†…å®¹..."):
            try:
                client = OpenAI(
                    api_key="sk-qseennfhdprismchczwnkzpohyjmuwgpiaywuclsisgugfvo",
                    base_url="https://api.siliconflow.cn/v1"
                )

                # ä½¿ç”¨ç»“æ„åŒ–æç¤º
                content_request = f"ä¸»é¢˜ï¼š{topic}ï¼Œçº§åˆ«ï¼š{level}"
                structured_prompt = create_structured_prompt(
                    content_request, "education_content")

                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™è‚²å†…å®¹ç”ŸæˆåŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼è¾“å‡ºæ•™è‚²å†…å®¹ã€‚"},
                        {"role": "user", "content": structured_prompt}
                    ],
                    temperature=0.1,  # é™ä½éšæœºæ€§ç¡®ä¿æ ¼å¼ç¨³å®š
                    max_tokens=max_tokens
                )

                content_result = response.choices[0].message.content

                # å°è¯•è§£æJSONå¹¶ç¾åŒ–æ˜¾ç¤º
                parsed_data = parse_json_response(content_result)

                if parsed_data:
                    # ç»“æ„åŒ–æ˜¾ç¤º
                    st.markdown(f"# {topic} - {level}çº§åˆ«æ•™è‚²å†…å®¹")

                    st.markdown("## ğŸ“š æ¦‚å¿µè§£é‡Š")
                    st.markdown(parsed_data.get(
                        'concept_explanation', 'æœªæä¾›è§£é‡Š'))

                    st.markdown("## ğŸ¯ å…³é”®è¦ç‚¹")
                    for i, point in enumerate(parsed_data.get('key_points', []), 1):
                        st.markdown(f"{i}. {point}")

                    st.markdown("## ğŸ’¡ å®é™…åº”ç”¨ç¤ºä¾‹")
                    for i, example in enumerate(parsed_data.get('examples', []), 1):
                        st.markdown(f"**ç¤ºä¾‹{i}**: {example}")

                    st.markdown("## ğŸ“ ç»ƒä¹ é¢˜")
                    exercises = parsed_data.get('exercises', [])
                    for i, exercise in enumerate(exercises, 1):
                        with st.expander(f"ç»ƒä¹ {i} ({exercise.get('difficulty', 'æœªçŸ¥')})"):
                            st.markdown(
                                f"**é—®é¢˜**: {exercise.get('question', 'æœªæä¾›')}")
                            st.markdown(
                                f"**ç­”æ¡ˆ**: {exercise.get('answer', 'æœªæä¾›')}")

                    st.markdown("## ğŸ“– è¿›ä¸€æ­¥å­¦ä¹ å»ºè®®")
                    for i, reading in enumerate(parsed_data.get('further_reading', []), 1):
                        st.markdown(f"{i}. {reading}")

                else:
                    # å¦‚æœJSONè§£æå¤±è´¥ï¼Œç›´æ¥æ˜¾ç¤ºåŸå§‹å›å¤
                    st.markdown(content_result)

            except Exception as e:
                st.error(f"APIè°ƒç”¨å‡ºé”™: {str(e)}")

elif app_mode == "å·¥å…·é›†æˆ":
    st.header("ğŸ› ï¸ å·¥å…·é›†æˆ")

    tool_tabs = st.tabs(["ä»£ç æ‰§è¡Œ", "ç½‘ç»œæœç´¢", "æ•°å­¦è®¡ç®—"])

    with tool_tabs[0]:
        st.subheader("Pythonä»£ç æ‰§è¡Œ")

        code = st.text_area(
            "è¾“å…¥Pythonä»£ç ",
            height=200,
            placeholder="# ç¤ºä¾‹ï¼šç»˜åˆ¶ç®€å•å›¾è¡¨\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\nplt.plot(x, y)\nplt.title('æ­£å¼¦å‡½æ•°')"
        )

        execute_button = st.button("æ‰§è¡Œä»£ç ", key="execute_code")

        if execute_button and code:
            with st.spinner("æ­£åœ¨æ‰§è¡Œä»£ç ..."):
                try:
                    # åˆ›å»ºè¾“å‡ºæ•è·å¯¹è±¡
                    from io import StringIO
                    import sys
                    import contextlib

                    # æ•è·æ ‡å‡†è¾“å‡º
                    stdout_capture = StringIO()

                    # åˆ›å»ºä¸€ä¸ªå›¾è¡¨å®¹å™¨ç”¨äºæ˜¾ç¤ºmatplotlibå›¾è¡¨
                    fig_container = st.empty()

                    # é‡å®šå‘æ ‡å‡†è¾“å‡ºå¹¶æ‰§è¡Œä»£ç 
                    with contextlib.redirect_stdout(stdout_capture):
                        # åˆ›å»ºæœ¬åœ°å˜é‡ç¯å¢ƒ
                        local_vars = {}

                        # å¦‚æœä»£ç ä¸­åŒ…å«matplotlibï¼Œæ·»åŠ ç‰¹æ®Šå¤„ç†
                        if "plt" in code:
                            # æ·»åŠ è‡ªåŠ¨æ˜¾ç¤ºå›¾è¡¨çš„ä»£ç 
                            exec_code = code + "\n\n# æ•è·å›¾è¡¨\nif 'plt' in locals() or 'plt' in globals():\n    fig = plt.gcf()\n    plt.close()"
                        else:
                            exec_code = code

                        # æ‰§è¡Œä»£ç 
                        exec(exec_code, globals(), local_vars)

                        # å¦‚æœç”Ÿæˆäº†å›¾è¡¨ï¼Œæ˜¾ç¤ºå®ƒ
                        if "plt" in code and "fig" in local_vars:
                            fig_container.pyplot(local_vars["fig"])

                    # è·å–æ ‡å‡†è¾“å‡º
                    output = stdout_capture.getvalue()

                    st.success("ä»£ç æ‰§è¡ŒæˆåŠŸï¼")
                    if output:
                        st.code(f"è¾“å‡ºï¼š\n{output}", language="text")
                    else:
                        st.code("è¾“å‡ºï¼š\n(æ— æ ‡å‡†è¾“å‡º)", language="text")

                except Exception as e:
                    st.error(f"ä»£ç æ‰§è¡Œå¤±è´¥ï¼š{str(e)}")
                    import traceback
                    st.code(f"é”™è¯¯è¯¦æƒ…ï¼š\n{traceback.format_exc()}",
                            language="python")

    with tool_tabs[1]:
        st.subheader("DuckDuckGoç½‘ç»œæœç´¢")

        search_query = st.text_input("è¾“å…¥æœç´¢å…³é”®è¯")
        search_button = st.button("æœç´¢", key="search")

        if search_button and search_query:
            with st.spinner(f"æ­£åœ¨æœç´¢ã€Œ{search_query}ã€..."):
                try:
                    with DDGS() as ddgs:
                        results = list(ddgs.text(search_query, max_results=5))

                    # æ˜¾ç¤ºæœç´¢ç»“æœ
                    if results:
                        for i, result in enumerate(results):
                            st.markdown(f"### æœç´¢ç»“æœ {i+1}")
                            st.markdown(f"**{result['title']}**")
                            st.markdown(f"{result['body']}")
                            st.markdown(
                                f"[{result['href']}]({result['href']})")
                    else:
                        st.info("æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")

                except Exception as e:
                    st.error(f"æœç´¢å‡ºé”™: {str(e)}")

    with tool_tabs[2]:
        st.subheader("æ•°å­¦è®¡ç®—")

        expression = st.text_input(
            "è¾“å…¥æ•°å­¦è¡¨è¾¾å¼",
            placeholder="ä¾‹å¦‚ï¼š(5 + 3) * 2 æˆ– np.sin(np.pi/2)"
        )

        calculate_button = st.button("è®¡ç®—", key="calculate")

        if calculate_button and expression:
            with st.spinner(f"æ­£åœ¨è®¡ç®—ã€Œ{expression}ã€..."):
                try:
                    # å¯¼å…¥å¸¸ç”¨çš„æ•°å­¦åº“

                    # å®‰å…¨åœ°è¯„ä¼°è¡¨è¾¾å¼
                    result = eval(expression)

                    # æ ¼å¼åŒ–ç»“æœ
                    if isinstance(result, (int, float, complex, np.number)):
                        formatted_result = f"{result}"
                        if isinstance(result, float) or isinstance(result, np.floating):
                            # å¯¹äºæµ®ç‚¹æ•°ï¼Œé™åˆ¶å°æ•°ä½æ•°
                            formatted_result = f"{result:.8g}"
                    elif isinstance(result, np.ndarray):
                        if result.size <= 10:  # å¦‚æœæ˜¯å°æ•°ç»„ï¼Œå®Œæ•´æ˜¾ç¤º
                            formatted_result = f"{result}"
                        else:  # å¦‚æœæ˜¯å¤§æ•°ç»„ï¼Œæ˜¾ç¤ºå½¢çŠ¶å’Œéƒ¨åˆ†å†…å®¹
                            formatted_result = f"æ•°ç»„å½¢çŠ¶: {result.shape}\nå‰å‡ ä¸ªå…ƒç´ : {result.flatten()[:5]}..."
                    else:
                        formatted_result = str(result)

                    st.success(f"è®¡ç®—ç»“æœï¼š{formatted_result}")

                    # å°è¯•ä½¿ç”¨LaTeXæ˜¾ç¤ºè¡¨è¾¾å¼å’Œç»“æœ
                    try:
                        st.latex(f"{expression} = {formatted_result}")
                    except:
                        st.text(f"{expression} = {formatted_result}")

                    # å¦‚æœç»“æœæ˜¯æ•°ç»„ä¸”å¤§å°é€‚ä¸­ï¼Œæ˜¾ç¤ºå›¾è¡¨
                    if isinstance(result, np.ndarray) and 1 < result.size <= 1000:
                        try:
                            import matplotlib.pyplot as plt
                            fig, ax = plt.subplots()

                            if result.ndim == 1:  # ä¸€ç»´æ•°ç»„
                                ax.plot(result)
                                ax.set_title("è®¡ç®—ç»“æœå¯è§†åŒ–")
                                ax.set_xlabel("ç´¢å¼•")
                                ax.set_ylabel("å€¼")
                            # äºŒç»´æ•°ç»„
                            elif result.ndim == 2 and min(result.shape) <= 50:
                                ax.imshow(result, cmap='viridis')
                                ax.set_title("äºŒç»´æ•°ç»„å¯è§†åŒ–")

                            st.pyplot(fig)
                        except Exception as viz_error:
                            st.info(f"æ— æ³•å¯è§†åŒ–ç»“æœ: {str(viz_error)}")

                except Exception as e:
                    st.error(f"è®¡ç®—é”™è¯¯: {str(e)}")
                    st.info("æç¤ºï¼šæ‚¨å¯ä»¥ä½¿ç”¨Pythonè¯­æ³•ï¼ŒåŒ…æ‹¬numpy (np)ã€mathåº“çš„å‡½æ•°")
                    st.code("""
    ç¤ºä¾‹:
    - åŸºæœ¬è¿ç®—: (5 + 3) * 2
    - ä¸‰è§’å‡½æ•°: np.sin(np.pi/2)
    - å¯¹æ•°: math.log(100, 10)
    - æ•°ç»„: np.array([1, 2, 3]) * 5
    - ç»Ÿè®¡: np.mean([1, 2, 3, 4, 5])
                    """)

# é¡µè„š
st.markdown("---")
st.markdown("Â© 2025 Chat-AI | åŸºäºå¤šç§LLMæ¨¡å‹æ„å»º")
