from backend.utils.prompt_templates import prompt_manager
from backend.utils.validation import validator, PAPER_ANALYSIS_SCHEMA, EDUCATION_CONTENT_SCHEMA, CHAT_MESSAGE_SCHEMA
from backend.utils.feedback_system import *
from duckduckgo_search import DDGS
import streamlit as st
import requests
import json
import time
import base64
from PIL import Image
import io
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from openai import OpenAI
import math
from scipy import stats, optimize, integrate
import speech_recognition as sr
import tempfile
import os
import re
from typing import Dict, Any, Optional
from datetime import datetime
import contextlib
from io import StringIO
import sys
import traceback
from backend.utils.feedback_system import feedback_system

project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)


# ==================== é¡µé¢é…ç½® ====================
st.set_page_config(
    page_title="Chat-AI",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# éšè—é»˜è®¤UIå…ƒç´ 
hide_default_format = """
<style>
#MainMenu {visibility: hidden; }
footer {visibility: hidden;}
header {visibility: hidden;}
.stDeployButton {display:none;}
</style>
"""
st.markdown(hide_default_format, unsafe_allow_html=True)

API_BASE_URL = "http://localhost:8000/api"
API_KEY = "sk-qseennfhdprismchczwnkzpohyjmuwgpiaywuclsisgugfvo"
BASE_URL = "https://api.siliconflow.cn/v1"

# å¤šæ¨¡æ€å¤„ç†å‡½æ•°


def encode_image_to_base64(image):
    """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"


def process_audio_to_text(audio_bytes):
    """å¤„ç†éŸ³é¢‘è½¬æ–‡æœ¬"""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_bytes)
            tmp_file_path = tmp_file.name

        recognizer = sr.Recognizer()

        try:
            with sr.AudioFile(tmp_file_path) as source:
                audio = recognizer.record(source)
                text = recognizer.recognize_google(audio, language='zh-CN')
        except:
            try:
                with sr.AudioFile(tmp_file_path) as source:
                    recognizer.adjust_for_ambient_noise(source)
                    audio = recognizer.record(source)
                    text = recognizer.recognize_google(audio, language='zh-CN')
            except Exception as e:
                raise e

        os.unlink(tmp_file_path)
        return text
    except Exception as e:
        return f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}"


def create_multimodal_message(text, image=None, audio_text=None):
    """åˆ›å»ºå¤šæ¨¡æ€æ¶ˆæ¯"""
    content = []

    if text:
        content.append({"type": "text", "text": text})

    if audio_text and not audio_text.startswith("è¯­éŸ³è¯†åˆ«å¤±è´¥"):
        content.append({"type": "text", "text": f"[è¯­éŸ³è¾“å…¥]: {audio_text}"})

    if image:
        image_base64 = encode_image_to_base64(image)
        content.append({
            "type": "image_url",
            "image_url": {"url": image_base64}
        })

    return content if len(content) > 0 else [{"type": "text", "text": ""}]

# ==================== åŠŸèƒ½æ¨¡å— ====================


def handle_chat_assistant(model, temperature, max_tokens):
    """å¤„ç†èŠå¤©åŠ©æ‰‹åŠŸèƒ½"""
    st.header("ğŸ’¬ èŠå¤©åŠ©æ‰‹")
    st.session_state.current_app_mode = "èŠå¤©åŠ©æ‰‹"

    # åˆå§‹åŒ–åé¦ˆç³»ç»Ÿ
    feedback_system.init_session_state()

    # æ·»åŠ è‡ªå®šä¹‰CSS
    st.markdown("""
    <style>
      div[data-testid="stFileUploader"] > label { display: none !important; }
      #file-input, #audio-input { display: none; }

      div[data-testid="stFileUploader"] > div:first-child > div:first-child > div:first-child {
            display: none !important;
        }

        div[data-testid="stFileUploader"]:before {
            content: "æ‹–æ‹½æ–‡ä»¶åˆ°è¿™é‡Œæˆ–ç‚¹å‡»æµè§ˆ";
            display: block;
            text-align: center;
            color: #666;
            font-size: 14px;
            margin-bottom: 10px;
        }

      .upload-btn {
        flex: none; width: 32px; height: 32px;
        margin-left: 8px; margin-right: 8px;
        border-radius: 50%; background: #fff;
        box-shadow: 0 1px 3px rgba(0,0,0,0.2);
        cursor: pointer; display: flex;
        align-items: center; justify-content: center;
        font-size: 18px; transition: transform .2s, box-shadow .2s;
      }
      .upload-btn:hover {
        transform: scale(1.1);
        box-shadow: 0 2px 6px rgba(0,0,0,0.3);
      }
    </style>
    """, unsafe_allow_html=True)

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'pending_files' not in st.session_state:
        st.session_state.pending_files = {'image': None, 'audio': None}

    # ğŸ”¥ ä¿®æ”¹è¿™æ•´ä¸ªéƒ¨åˆ†ï¼šæ˜¾ç¤ºèŠå¤©å†å²å¹¶ä¸ºæ¯ä¸ªåŠ©æ‰‹å›å¤æ·»åŠ åé¦ˆè¡¨å•
    for i, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            if isinstance(message["content"], str):
                st.markdown(message["content"])
            else:
                for content_item in message["content"]:
                    if content_item["type"] == "text":
                        st.markdown(content_item["text"])
                    elif content_item["type"] == "image_url":
                        st.image(content_item["image_url"]["url"], width=300)

            # ğŸ”¥ ä¸ºæ¯ä¸ªåŠ©æ‰‹å›å¤æ·»åŠ åé¦ˆè¡¨å•
            if message["role"] == "assistant":
                # ä½¿ç”¨æ¶ˆæ¯ç´¢å¼•å’Œå†…å®¹å“ˆå¸Œåˆ›å»ºå”¯ä¸€ID
                message_content = message["content"] if isinstance(
                    message["content"], str) else str(message["content"])
                message_hash = str(hash(message_content[:100]))
                interaction_id = f"chat_msg_{i}_{message_hash}"

                # æ£€æŸ¥æ˜¯å¦å·²ç»æäº¤è¿‡åé¦ˆ
                feedback_key = f"feedback_{interaction_id}"
                is_submitted = st.session_state.get(
                    feedback_key, {}).get('submitted', False)

                if not is_submitted:
                    with st.expander("ğŸ“ ä¸ºè¿™æ¬¡å›ç­”è¯„åˆ†", expanded=False):
                        feedback_system.show_feedback_form(interaction_id)
                else:
                    st.success("âœ… å·²æäº¤åé¦ˆ")

    # æ–‡ä»¶ä¸Šä¼ å™¨
    with st.container():
        col1, col2 = st.columns(2)

        with col1:
            uploaded_image = st.file_uploader(
                "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶",
                type=['png', 'jpg', 'jpeg', 'gif', 'webp'],
                key=f"img_uploader_{st.session_state.get('upload_counter', 0)}",
                label_visibility="collapsed"
            )

        with col2:
            uploaded_audio = st.file_uploader(
                "é€‰æ‹©éŸ³é¢‘æ–‡ä»¶",
                type=['wav', 'mp3', 'm4a', 'ogg'],
                key=f"audio_uploader_{st.session_state.get('upload_counter', 0)}",
                label_visibility="collapsed"
            )

    # å¤„ç†æ–‡ä»¶ä¸Šä¼ 
    if uploaded_image:
        st.session_state.pending_files['image'] = uploaded_image
        st.success("âœ… å›¾ç‰‡å·²é€‰æ‹©ï¼è¯·è¾“å…¥æ¶ˆæ¯åå‘é€")

    if uploaded_audio:
        st.session_state.pending_files['audio'] = uploaded_audio
        st.success("âœ… éŸ³é¢‘å·²é€‰æ‹©ï¼è¯·è¾“å…¥æ¶ˆæ¯åå‘é€")

    # æ˜¾ç¤ºæ–‡ä»¶é¢„è§ˆ
    if st.session_state.pending_files['image']:
        st.markdown("ğŸ“· **å¾…å‘é€å›¾ç‰‡:**")
        try:
            image = Image.open(st.session_state.pending_files['image'])
            st.image(image, width=200)
        except Exception as e:
            st.error(f"å›¾ç‰‡é¢„è§ˆå¤±è´¥: {str(e)}")

    if st.session_state.pending_files['audio']:
        st.markdown("ğŸ¤ **å¾…å‘é€éŸ³é¢‘:**")
        try:
            st.audio(st.session_state.pending_files['audio'])
        except Exception as e:
            st.error(f"éŸ³é¢‘é¢„è§ˆå¤±è´¥: {str(e)}")

    # èŠå¤©è¾“å…¥æ¡†
    prompt = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")

    # JavaScriptæŒ‰é’®ï¼ˆä¿æŒåŸæœ‰åŠŸèƒ½ï¼‰
    st.markdown("""
    <script>
    (function() {
      function insertButtons() {
        const container = document.querySelector('div[data-testid="stChatInput"]');
        if (!container || container.querySelector('.upload-btn')) return;

        container.insertAdjacentHTML('afterbegin', `
          <label for="file-input"  class="upload-btn" title="ä¸Šä¼ å›¾ç‰‡">ğŸ“·</label>
          <label for="audio-input" class="upload-btn" title="ä¸Šä¼ éŸ³é¢‘">ğŸ¤</label>
          <input type="file" id="file-input"  accept="image/*">
          <input type="file" id="audio-input" accept="audio/*">
        `);
      }

      window.addEventListener('click', e => {
        if (e.target.matches('.upload-btn[title="ä¸Šä¼ å›¾ç‰‡"]'))
          document.getElementById('file-input').click();
        if (e.target.matches('.upload-btn[title="ä¸Šä¼ éŸ³é¢‘"]'))
          document.getElementById('audio-input').click();
      });

      if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', insertButtons);
      } else {
        insertButtons();
      }
      new MutationObserver(insertButtons).observe(document.body, {
        childList: true, subtree: true
      });
    })();
    </script>
    """, unsafe_allow_html=True)

    # å¤„ç†ç”¨æˆ·è¾“å…¥
    if prompt:
        audio_text = None
        image = None

        # å¤„ç†è¯­éŸ³
        if st.session_state.pending_files['audio']:
            with st.spinner("ğŸ¤ æ­£åœ¨è¯†åˆ«è¯­éŸ³..."):
                try:
                    audio_bytes = st.session_state.pending_files['audio'].read(
                    )
                    audio_text = process_audio_to_text(audio_bytes)
                    st.session_state.pending_files['audio'].seek(0)
                except Exception as e:
                    audio_text = f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}"

        # å¤„ç†å›¾ç‰‡
        if st.session_state.pending_files['image']:
            try:
                image = Image.open(st.session_state.pending_files['image'])
                st.session_state.pending_files['image'].seek(0)
            except Exception as e:
                st.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}")
                image = None

        # åˆ›å»ºæ¶ˆæ¯
        user_content = create_multimodal_message(prompt, image, audio_text)
        current_model = "Qwen/Qwen2.5-VL-72B-Instruct" if image else model

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append(
            {"role": "user", "content": user_content})

        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(prompt)
            if audio_text and not audio_text.startswith("è¯­éŸ³è¯†åˆ«å¤±è´¥"):
                st.markdown(f"ğŸ¤ **è¯­éŸ³è¾“å…¥**: {audio_text}")
            if image:
                st.image(image, width=300)

        # æ¸…é™¤æ–‡ä»¶
        st.session_state.pending_files = {'image': None, 'audio': None}
        st.session_state.upload_counter = st.session_state.get(
            'upload_counter', 0) + 1

        # ç”ŸæˆAIå›å¤
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""

            try:
                client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æä¸æ•™è‚²è¾…å¯¼åŠ©æ‰‹ï¼Œæ“…é•¿å¸®åŠ©ç”¨æˆ·è§£ç­”å­¦æœ¯é—®é¢˜ã€åˆ†æè®ºæ–‡å’Œæä¾›æ•™è‚²æŒ‡å¯¼ã€‚å½“ç”¨æˆ·æä¾›å›¾ç‰‡æ—¶ï¼Œè¯·è¯¦ç»†æè¿°å›¾ç‰‡å†…å®¹å¹¶å›ç­”ç›¸å…³é—®é¢˜ã€‚"}
                ]

                recent_messages = st.session_state.messages[-10:] if len(
                    st.session_state.messages) > 10 else st.session_state.messages

                for msg in recent_messages:
                    messages.append(
                        {"role": msg["role"], "content": msg["content"]})

                response = client.chat.completions.create(
                    model=current_model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    stream=True
                )

                for chunk in response:
                    if chunk.choices[0].delta.content is not None:
                        content = chunk.choices[0].delta.content
                        full_response += content
                        message_placeholder.markdown(full_response + "â–Œ")
                        time.sleep(0.01)

                message_placeholder.markdown(full_response)

            except Exception as e:
                error_message = f"APIè°ƒç”¨å‡ºé”™: {str(e)}"
                message_placeholder.error(error_message)
                full_response = error_message

            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
            st.session_state.messages.append(
                {"role": "assistant", "content": full_response})

        # ğŸ”¥ ä¿®æ”¹æ–°å›å¤åçš„åé¦ˆè¡¨å•ï¼ˆçº¦ç¬¬230-250è¡Œï¼‰
        if full_response and not full_response.startswith("APIè°ƒç”¨å‡ºé”™"):
            # ä¸ºæœ€æ–°çš„å›å¤åˆ›å»ºåé¦ˆè¡¨å•
            latest_msg_index = len(st.session_state.messages) - 1
            message_hash = str(hash(full_response[:100]))
            new_interaction_id = f"chat_msg_{latest_msg_index}_{message_hash}"

            st.markdown("---")

            # ğŸ”¥ ä½¿ç”¨å®¹å™¨æ¥ç¡®ä¿ç¨³å®šæ˜¾ç¤º
            with st.container():
                feedback_system.show_feedback_form(new_interaction_id)


def handle_paper_analysis(model, max_tokens):
    """å¤„ç†è®ºæ–‡åˆ†æåŠŸèƒ½"""
    st.header("ğŸ“ è®ºæ–‡åˆ†æ")
    st.session_state.current_app_mode = "è®ºæ–‡åˆ†æ"

    # åˆå§‹åŒ–åé¦ˆç³»ç»Ÿ
    feedback_system.init_session_state()

    # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šæ¬¡åˆ†æçš„ç»“æœ
    if 'last_paper_analysis' in st.session_state:
        analysis_data = st.session_state.last_paper_analysis

        with st.expander("ğŸ“Š æŸ¥çœ‹ä¸Šæ¬¡åˆ†æç»“æœ", expanded=True):
            st.markdown(f"**åˆ†ææ—¶é—´**: {analysis_data.get('analyzed_at', 'æœªçŸ¥')}")
            st.markdown(
                f"**è®ºæ–‡å­—æ•°**: {len(analysis_data.get('original_text', ''))} å­—ç¬¦")

            # æ˜¾ç¤ºåˆ†æç»“æœ
            display_paper_analysis_results(analysis_data['analysis_result'])

            # æ˜¾ç¤ºåé¦ˆè¡¨å•
            interaction_id = analysis_data.get('interaction_id')
            if interaction_id:
                st.markdown("---")
                st.markdown("### ğŸ“ åˆ†æè¯„ä»·")
                st.info("ğŸ“Š ä¸ºè¿™æ¬¡è®ºæ–‡åˆ†æçš„è´¨é‡è¯„åˆ†")
                feedback_system.show_feedback_form(interaction_id)

        # æ¸…é™¤æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…é™¤ä¸Šæ¬¡åˆ†æ", key="clear_last_analysis"):
            del st.session_state.last_paper_analysis
            st.rerun()

        st.markdown("---")
        st.markdown("### ğŸ†• åˆ†ææ–°è®ºæ–‡")

    # è¾“å…¥ç•Œé¢
    paper_text = st.text_area(
        "è¯·è¾“å…¥è®ºæ–‡æ–‡æœ¬æˆ–æ‘˜è¦",
        height=300,
        help="ç²˜è´´è®ºæ–‡æ–‡æœ¬ã€æ‘˜è¦æˆ–PDFæå–çš„å†…å®¹"
    )

    col1, col2 = st.columns([1, 3])
    with col1:
        analyze_button = st.button("åˆ†æè®ºæ–‡", type="primary")

    if analyze_button and paper_text:
        # è¾“å…¥éªŒè¯
        input_data = {"text": paper_text}
        is_valid_input, input_error = validator.validate_input_data(
            input_data, "paper_text")

        if not is_valid_input:
            st.error(f"âŒ è¾“å…¥éªŒè¯å¤±è´¥: {input_error}")
            st.stop()

        with st.spinner("æ­£åœ¨åˆ†æè®ºæ–‡..."):
            try:
                client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

                # ä½¿ç”¨æ¨¡æ¿ç®¡ç†å™¨ç”Ÿæˆæç¤ºè¯
                structured_prompt = prompt_manager.create_structured_prompt(
                    paper_text, "paper_analysis")

                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æåŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœã€‚"},
                        {"role": "user", "content": structured_prompt}
                    ],
                    temperature=0.1,
                    max_tokens=max_tokens
                )

                analysis_result = response.choices[0].message.content

                # éªŒè¯ç»“æœ
                parsed_data, is_valid, error_msg = validator.safe_parse_json_response(
                    analysis_result, PAPER_ANALYSIS_SCHEMA, "è®ºæ–‡åˆ†æ"
                )

                if is_valid and parsed_data:
                    st.success("âœ… è®ºæ–‡åˆ†æå®Œæˆï¼Œæ ¼å¼éªŒè¯é€šè¿‡")

                    # ğŸ”¥ ç”Ÿæˆå”¯ä¸€IDå¹¶ä¿å­˜åˆ†æç»“æœ
                    interaction_id = f"paper_analysis_{int(time.time() * 1000)}"

                    # ä¿å­˜åˆ°session_state
                    st.session_state.last_paper_analysis = {
                        'original_text': paper_text,
                        'analysis_result': parsed_data,
                        'interaction_id': interaction_id,
                        'analyzed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    }

                    # æ˜¾ç¤ºåˆ†æç»“æœ
                    display_paper_analysis_results(parsed_data)

                    # æ˜¾ç¤ºåé¦ˆè¡¨å•
                    with st.expander("ğŸ“ ä¸ºè¿™æ¬¡åˆ†æè¯„åˆ†", expanded=False):
                        st.info("ğŸ“Š ä¸ºè¿™æ¬¡è®ºæ–‡åˆ†æçš„è´¨é‡è¯„åˆ†")
                        feedback_system.show_feedback_form(interaction_id)

                else:
                    st.warning(f"âš ï¸ {error_msg}")
                    st.markdown("### ğŸ“„ åŸå§‹AIå›å¤")
                    st.markdown(analysis_result)

                    if st.button("ğŸ”„ é‡æ–°åˆ†æ", key="retry_analysis"):
                        st.rerun()

            except Exception as e:
                st.error(f"âŒ APIè°ƒç”¨å‡ºé”™: {str(e)}")


def display_paper_analysis_results(parsed_data):
    """æ˜¾ç¤ºè®ºæ–‡åˆ†æç»“æœçš„è¾…åŠ©å‡½æ•°"""
    st.markdown("### ğŸ“Š è®ºæ–‡åˆ†æç»“æœ")

    st.markdown("### ğŸ“ æ‘˜è¦æ€»ç»“")
    st.markdown(parsed_data['summary'])

    st.markdown("### ğŸ¯ ä¸»è¦è´¡çŒ®")
    for i, contrib in enumerate(parsed_data['main_contributions'], 1):
        st.markdown(f"{i}. {contrib}")

    st.markdown("### ğŸ”¬ ç ”ç©¶æ–¹æ³•")
    st.markdown(parsed_data['methodology'])

    st.markdown("### ğŸ” å…³é”®å‘ç°")
    for i, finding in enumerate(parsed_data['key_findings'], 1):
        st.markdown(f"{i}. {finding}")

    st.markdown("### âš ï¸ ç ”ç©¶å±€é™")
    for i, limitation in enumerate(parsed_data['limitations'], 1):
        st.markdown(f"{i}. {limitation}")

    st.markdown("### ğŸ’¡ ç ”ç©¶æ„ä¹‰")
    st.markdown(parsed_data['significance'])


def display_education_content(parsed_data, topic, level, use_expanders=True):
    """æ˜¾ç¤ºæ•™è‚²å†…å®¹çš„è¾…åŠ©å‡½æ•°"""
    st.markdown(f"# {topic} - {level}çº§åˆ«æ•™è‚²å†…å®¹")

    st.markdown("## ğŸ“š æ¦‚å¿µè§£é‡Š")
    st.markdown(parsed_data['concept_explanation'])

    st.markdown("## ğŸ¯ å…³é”®è¦ç‚¹")
    for i, point in enumerate(parsed_data['key_points'], 1):
        st.markdown(f"{i}. {point}")

    st.markdown("## ğŸ’¡ å®é™…åº”ç”¨ç¤ºä¾‹")
    for i, example in enumerate(parsed_data['examples'], 1):
        st.markdown(f"**ç¤ºä¾‹{i}**: {example}")

    st.markdown("## ğŸ“ ç»ƒä¹ é¢˜")
    for i, exercise in enumerate(parsed_data['exercises'], 1):
        # ğŸ”¥ æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦ä½¿ç”¨expander
        if use_expanders:
            with st.expander(f"ç»ƒä¹ {i} ({exercise['difficulty']})"):
                st.markdown(f"**é—®é¢˜**: {exercise['question']}")
                st.markdown(f"**ç­”æ¡ˆ**: {exercise['answer']}")
        else:
            # ğŸ”¥ ä¸ä½¿ç”¨expanderï¼Œç›´æ¥æ˜¾ç¤º
            st.markdown(f"### ç»ƒä¹ {i} ({exercise['difficulty']})")
            st.markdown(f"**é—®é¢˜**: {exercise['question']}")

            # ä½¿ç”¨è¯¦æƒ…æ ‡ç­¾æ¥éšè—ç­”æ¡ˆ
            with st.container():
                if st.button(f"æ˜¾ç¤ºç­”æ¡ˆ {i}", key=f"show_answer_{i}_{topic}_{level}"):
                    st.markdown(f"**ç­”æ¡ˆ**: {exercise['answer']}")

    st.markdown("## ğŸ“– è¿›ä¸€æ­¥å­¦ä¹ å»ºè®®")
    for i, reading in enumerate(parsed_data['further_reading'], 1):
        st.markdown(f"{i}. {reading}")


def handle_education_content(model, max_tokens):
    """å¤„ç†æ•™è‚²å†…å®¹ç”ŸæˆåŠŸèƒ½"""
    st.header("ğŸ“ æ•™è‚²å†…å®¹ç”Ÿæˆ")
    st.session_state.current_app_mode = "æ•™è‚²å†…å®¹ç”Ÿæˆ"

    # åˆå§‹åŒ–åé¦ˆç³»ç»Ÿ
    feedback_system.init_session_state()

    # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šæ¬¡ç”Ÿæˆçš„å†…å®¹
    if 'last_generated_content' in st.session_state:
        content_data = st.session_state.last_generated_content

        with st.expander("ğŸ“š æŸ¥çœ‹ä¸Šæ¬¡ç”Ÿæˆçš„å†…å®¹", expanded=True):
            st.markdown(
                f"**ä¸»é¢˜**: {content_data['topic']} | **çº§åˆ«**: {content_data['level']}")

            # ğŸ”¥ æ˜¾ç¤ºå†…å®¹æ—¶ä¸ä½¿ç”¨expander
            display_education_content(
                content_data['content'],
                content_data['topic'],
                content_data['level'],
                use_expanders=False  # âœ… å…³é”®ä¿®æ”¹
            )

            # æ˜¾ç¤ºåé¦ˆè¡¨å•
            interaction_id = content_data.get('interaction_id')
            if interaction_id:
                st.markdown("---")
                st.markdown("### ğŸ“ å†…å®¹è¯„ä»·")
                st.info(
                    f"ğŸ“š ä¸»é¢˜: {content_data['topic']} | çº§åˆ«: {content_data['level']}")
                feedback_system.show_feedback_form(interaction_id)

        # æ¸…é™¤æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…é™¤ä¸Šæ¬¡å†…å®¹", key="clear_last_content"):
            del st.session_state.last_generated_content
            st.rerun()

        st.markdown("---")
        st.markdown("### ğŸ†• ç”Ÿæˆæ–°å†…å®¹")

    # è¾“å…¥ç•Œé¢
    col1, col2 = st.columns(2)

    with col1:
        topic = st.text_input("è¯·è¾“å…¥ä¸»é¢˜", placeholder="ä¾‹å¦‚ï¼šå…‰åˆä½œç”¨ã€å¾®ç§¯åˆ†ã€äººå·¥æ™ºèƒ½...")

    with col2:
        level = st.selectbox("é€‰æ‹©æ•™è‚²çº§åˆ«", ["å°å­¦", "åˆä¸­", "é«˜ä¸­", "å¤§å­¦", "ç ”ç©¶ç”Ÿ"])

    generate_button = st.button("ç”Ÿæˆæ•™è‚²å†…å®¹", type="primary")

    if generate_button and topic:
        # è¾“å…¥éªŒè¯
        input_data = {"topic": topic, "level": level}
        is_valid_input, input_error = validator.validate_input_data(
            input_data, "education_request")

        if not is_valid_input:
            st.error(f"âŒ è¾“å…¥éªŒè¯å¤±è´¥: {input_error}")
            st.stop()

        with st.spinner(f"æ­£åœ¨ç”Ÿæˆå…³äºã€Œ{topic}ã€çš„{level}çº§åˆ«æ•™è‚²å†…å®¹..."):
            try:
                client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

                content_request = f"ä¸»é¢˜ï¼š{topic}ï¼Œçº§åˆ«ï¼š{level}"
                structured_prompt = prompt_manager.create_structured_prompt(
                    content_request, "education_content")

                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™è‚²å†…å®¹ç”ŸæˆåŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼è¾“å‡ºæ•™è‚²å†…å®¹ã€‚"},
                        {"role": "user", "content": structured_prompt}
                    ],
                    temperature=0.1,
                    max_tokens=max_tokens
                )

                content_result = response.choices[0].message.content

                # éªŒè¯ç»“æœ
                parsed_data, is_valid, error_msg = validator.safe_parse_json_response(
                    content_result, EDUCATION_CONTENT_SCHEMA, "æ•™è‚²å†…å®¹"
                )

                if is_valid and parsed_data:
                    st.success("âœ… æ•™è‚²å†…å®¹ç”Ÿæˆå®Œæˆï¼Œæ ¼å¼éªŒè¯é€šè¿‡")

                    # ğŸ”¥ ç”Ÿæˆå”¯ä¸€IDå¹¶ä¿å­˜å†…å®¹
                    interaction_id = f"education_{topic}_{level}_{int(time.time() * 1000)}"

                    # ä¿å­˜åˆ°session_state
                    st.session_state.last_generated_content = {
                        'topic': topic,
                        'level': level,
                        'content': parsed_data,
                        'interaction_id': interaction_id,
                        'generated_at': datetime.now().isoformat()
                    }

                    # ğŸ”¥ æ˜¾ç¤ºå†…å®¹æ—¶ä½¿ç”¨expanderï¼ˆæ–°ç”Ÿæˆçš„å†…å®¹å¯ä»¥ä½¿ç”¨ï¼‰
                    display_education_content(
                        parsed_data, topic, level, use_expanders=True)

                    # æ˜¾ç¤ºåé¦ˆè¡¨å•
                    with st.expander("ğŸ“ ä¸ºè¿™æ¬¡å†…å®¹è¯„åˆ†", expanded=False):
                        st.info(f"ğŸ“š ä¸»é¢˜: {topic} | çº§åˆ«: {level}")
                        feedback_system.show_feedback_form(interaction_id)

                else:
                    st.warning(f"âš ï¸ {error_msg}")
                    st.markdown("### ğŸ“„ åŸå§‹AIå›å¤")
                    st.markdown(content_result)

                    if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆ", key="retry_generation"):
                        st.rerun()

            except Exception as e:
                st.error(f"âŒ APIè°ƒç”¨å‡ºé”™: {str(e)}")


def handle_tool_integration():
    """å¤„ç†å·¥å…·é›†æˆåŠŸèƒ½"""
    st.header("ğŸ› ï¸ å·¥å…·é›†æˆ")
    st.session_state.current_app_mode = "å·¥å…·é›†æˆ"

    tool_tabs = st.tabs(["ä»£ç æ‰§è¡Œ", "ç½‘ç»œæœç´¢", "æ•°å­¦è®¡ç®—"])

    with tool_tabs[0]:
        st.subheader("Pythonä»£ç æ‰§è¡Œ")

        code = st.text_area(
            "è¾“å…¥Pythonä»£ç ",
            height=200,
            placeholder="# ç¤ºä¾‹ï¼šç»˜åˆ¶ç®€å•å›¾è¡¨\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\nplt.plot(x, y)\nplt.title('æ­£å¼¦å‡½æ•°')"
        )

        execute_button = st.button("æ‰§è¡Œä»£ç ", key="execute_code")

        if execute_button and code:
            with st.spinner("æ­£åœ¨æ‰§è¡Œä»£ç ..."):
                try:
                    stdout_capture = StringIO()
                    fig_container = st.empty()

                    with contextlib.redirect_stdout(stdout_capture):
                        local_vars = {}

                        if "plt" in code:
                            exec_code = code + "\n\n# æ•è·å›¾è¡¨\nif 'plt' in locals() or 'plt' in globals():\n    fig = plt.gcf()\n    plt.close()"
                        else:
                            exec_code = code

                        exec(exec_code, globals(), local_vars)

                        if "plt" in code and "fig" in local_vars:
                            fig_container.pyplot(local_vars["fig"])

                    output = stdout_capture.getvalue()

                    st.success("ä»£ç æ‰§è¡ŒæˆåŠŸï¼")
                    if output:
                        st.code(f"è¾“å‡ºï¼š\n{output}", language="text")
                    else:
                        st.code("è¾“å‡ºï¼š\n(æ— æ ‡å‡†è¾“å‡º)", language="text")

                except Exception as e:
                    st.error(f"ä»£ç æ‰§è¡Œå¤±è´¥ï¼š{str(e)}")
                    st.code(f"é”™è¯¯è¯¦æƒ…ï¼š\n{traceback.format_exc()}",
                            language="python")

    with tool_tabs[1]:
        st.subheader("DuckDuckGoç½‘ç»œæœç´¢")

        search_query = st.text_input("è¾“å…¥æœç´¢å…³é”®è¯")
        search_button = st.button("æœç´¢", key="search")

        if search_button and search_query:
            with st.spinner(f"æ­£åœ¨æœç´¢ã€Œ{search_query}ã€..."):
                try:
                    with DDGS() as ddgs:
                        results = list(ddgs.text(search_query, max_results=5))

                    if results:
                        for i, result in enumerate(results):
                            st.markdown(f"### æœç´¢ç»“æœ {i+1}")
                            st.markdown(f"**{result['title']}**")
                            st.markdown(f"{result['body']}")
                            st.markdown(
                                f"[{result['href']}]({result['href']})")
                    else:
                        st.info("æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")

                except Exception as e:
                    st.error(f"æœç´¢å‡ºé”™: {str(e)}")

    with tool_tabs[2]:
        st.subheader("æ•°å­¦è®¡ç®—")

        expression = st.text_input(
            "è¾“å…¥æ•°å­¦è¡¨è¾¾å¼",
            placeholder="ä¾‹å¦‚ï¼š(5 + 3) * 2 æˆ– np.sin(np.pi/2)"
        )

        calculate_button = st.button("è®¡ç®—", key="calculate")

        if calculate_button and expression:
            with st.spinner(f"æ­£åœ¨è®¡ç®—ã€Œ{expression}ã€..."):
                try:
                    result = eval(expression)

                    if isinstance(result, (int, float, complex, np.number)):
                        formatted_result = f"{result}"
                        if isinstance(result, float) or isinstance(result, np.floating):
                            formatted_result = f"{result:.8g}"
                    elif isinstance(result, np.ndarray):
                        if result.size <= 10:
                            formatted_result = f"{result}"
                        else:
                            formatted_result = f"æ•°ç»„å½¢çŠ¶: {result.shape}\nå‰å‡ ä¸ªå…ƒç´ : {result.flatten()[:5]}..."
                    else:
                        formatted_result = str(result)

                    st.success(f"è®¡ç®—ç»“æœï¼š{formatted_result}")

                    try:
                        st.latex(f"{expression} = {formatted_result}")
                    except:
                        st.text(f"{expression} = {formatted_result}")

                    if isinstance(result, np.ndarray) and 1 < result.size <= 1000:
                        try:
                            fig, ax = plt.subplots()

                            if result.ndim == 1:
                                ax.plot(result)
                                ax.set_title("è®¡ç®—ç»“æœå¯è§†åŒ–")
                                ax.set_xlabel("ç´¢å¼•")
                                ax.set_ylabel("å€¼")
                            elif result.ndim == 2 and min(result.shape) <= 50:
                                ax.imshow(result, cmap='viridis')
                                ax.set_title("äºŒç»´æ•°ç»„å¯è§†åŒ–")

                            st.pyplot(fig)
                        except Exception as viz_error:
                            st.info(f"æ— æ³•å¯è§†åŒ–ç»“æœ: {str(viz_error)}")

                except Exception as e:
                    st.error(f"è®¡ç®—é”™è¯¯: {str(e)}")
                    st.info("æç¤ºï¼šæ‚¨å¯ä»¥ä½¿ç”¨Pythonè¯­æ³•ï¼ŒåŒ…æ‹¬numpy (np)ã€mathåº“çš„å‡½æ•°")
                    st.code("""
    ç¤ºä¾‹:
    - åŸºæœ¬è¿ç®—: (5 + 3) * 2
    - ä¸‰è§’å‡½æ•°: np.sin(np.pi/2)
    - å¯¹æ•°: math.log(100, 10)
    - æ•°ç»„: np.array([1, 2, 3]) * 5
    - ç»Ÿè®¡: np.mean([1, 2, 3, 4, 5])
                    """)

# ==================== ä¸»åº”ç”¨ ====================


def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    DEBUG_MODE = True
    # åˆå§‹åŒ– session state
    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(datetime.now().timestamp())
    feedback_system.init_session_state()

    # è®¾ç½®æ ‡é¢˜
    st.title("ğŸ“š Chat-AI")

    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("æ¨¡å‹è®¾ç½®")

        model_display = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["DeepSeek-V3", "Qwen-72B", "DeepSeek-R1"]
        )

        model_mapping = {
            "DeepSeek-V3": "Pro/deepseek-ai/DeepSeek-V3",
            "Qwen-72B": "Qwen/Qwen2.5-72B-Instruct",
            "DeepSeek-R1": "Pro/deepseek-ai/DeepSeek-R1"
        }

        model = model_mapping.get(model_display, "deepseek-chat")

        temperature = st.slider(
            "Temperature",
            min_value=0.0,
            max_value=2.0,
            value=0.7,
            step=0.1,
            help="å€¼è¶Šé«˜ï¼Œå›ç­”è¶Šå¤šæ ·åŒ–ï¼›å€¼è¶Šä½ï¼Œå›ç­”è¶Šç¡®å®šæ€§"
        )

        max_tokens = st.slider(
            "æœ€å¤§ç”Ÿæˆé•¿åº¦",
            min_value=100,
            max_value=4000,
            value=1000,
            step=100,
            help="æ§åˆ¶å›ç­”çš„æœ€å¤§é•¿åº¦"
        )

        st.divider()

        st.header("åŠŸèƒ½é€‰æ‹©")
        app_mode = st.radio(
            "é€‰æ‹©åŠŸèƒ½",
            ["èŠå¤©åŠ©æ‰‹", "è®ºæ–‡åˆ†æ", "æ•™è‚²å†…å®¹ç”Ÿæˆ", "å·¥å…·é›†æˆ"]
        )

        st.divider()
        st.header("ğŸ” æ•°æ®éªŒè¯")

        if st.checkbox("æ˜¾ç¤ºSchemaè¯¦æƒ…", help="æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„JSON Schemaè§„èŒƒ"):
            if app_mode == "è®ºæ–‡åˆ†æ":
                st.json(PAPER_ANALYSIS_SCHEMA)
            elif app_mode == "æ•™è‚²å†…å®¹ç”Ÿæˆ":
                st.json(EDUCATION_CONTENT_SCHEMA)
            elif app_mode == "èŠå¤©åŠ©æ‰‹":
                st.json(CHAT_MESSAGE_SCHEMA)

        # ğŸ”¥ å®Œå…¨æ›¿æ¢è¿™æ•´ä¸ªéƒ¨åˆ†ï¼šåé¦ˆç»Ÿè®¡éƒ¨åˆ†
        st.divider()
        st.header("ğŸ“Š åé¦ˆç»Ÿè®¡")

        # æ·»åŠ æ“ä½œæŒ‰é’®
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ åˆ·æ–°", key="refresh_feedback", help="é‡æ–°åŠ è½½åé¦ˆæ•°æ®"):
                # å¼ºåˆ¶é‡æ–°åŠ è½½æ•°æ®
                feedback_system.force_refresh_data()
                st.success("âœ… æ•°æ®å·²åˆ·æ–°")
                st.rerun()

        with col2:
            if st.button("ğŸ“‹ è¯¦æƒ…", key="show_detail", help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯"):
                st.session_state.show_feedback_detail = not st.session_state.get(
                    'show_feedback_detail', False)

        # æ˜¾ç¤ºåé¦ˆç»Ÿè®¡
        feedback_system.show_feedback_stats()

    # ğŸ”¥ å®Œå…¨æ›¿æ¢è¿™ä¸ªéƒ¨åˆ†
    if st.session_state.get('show_feedback_detail', False):
        st.markdown("---")
        st.subheader("ğŸ” è¯¦ç»†ä¿¡æ¯")

        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        feedback_data = st.session_state.get('feedback_data', [])
        interaction_feedback = st.session_state.get('interaction_feedback', {})

        st.write(f"**Sessionåé¦ˆ:** {len(feedback_data)} æ¡")
        st.write(f"**å·²æ ‡è®°äº¤äº’:** {len(interaction_feedback)} ä¸ª")

        # ğŸ”¥ æ£€æŸ¥æ–‡ä»¶çŠ¶æ€ - ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å˜é‡å
        data_file_path = feedback_system.data_file  # âœ… ä½¿ç”¨ data_file
        if os.path.exists(data_file_path):
            try:
                with open(data_file_path, 'r', encoding='utf-8') as f:
                    file_data = json.load(f)
                st.write(f"**æ–‡ä»¶åé¦ˆ:** {len(file_data)} æ¡")
                st.write(f"**æ–‡ä»¶è·¯å¾„:** {data_file_path}")
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        else:
            st.write("**æ–‡ä»¶çŠ¶æ€:** ğŸ“„ ä¸å­˜åœ¨")
            st.write(f"**é¢„æœŸè·¯å¾„:** {data_file_path}")

        # æ˜¾ç¤ºæœ€è¿‘çš„åé¦ˆ
        if feedback_data:
            st.write("**æœ€è¿‘åé¦ˆ:**")
            for i, feedback in enumerate(feedback_data[-2:]):  # åªæ˜¾ç¤ºæœ€è¿‘2æ¡
                rating = feedback.get(
                    'average_rating', feedback.get('rating', 0))
                fb_type = feedback.get('feedback_type', 'æœªçŸ¥')
                timestamp = feedback.get('timestamp', '')

                if timestamp:
                    try:
                        dt = datetime.fromisoformat(
                            timestamp.replace('Z', '+00:00'))
                        time_str = dt.strftime('%m-%d %H:%M')
                    except:
                        time_str = timestamp[:16]
                else:
                    time_str = 'æœªçŸ¥æ—¶é—´'

                st.write(f"â€¢ â­{rating:.1f} - {fb_type} ({time_str})")

        # ğŸ”¥ ç®¡ç†æ“ä½œéƒ¨åˆ†
        st.markdown("**ç®¡ç†æ“ä½œ:**")
        col3, col4 = st.columns(2)

        with col3:
            if st.button("ğŸ“Š å¯¼å‡ºCSV", key="export_csv", help="å¯¼å‡ºåé¦ˆæ•°æ®"):
                csv_data = feedback_system.export_feedback_data()
                if csv_data:
                    filename = f"feedback_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½æ•°æ®",
                        data=csv_data,
                        file_name=filename,
                        mime="text/csv",
                        key="download_csv"
                    )
                else:
                    st.warning("âš ï¸ æš‚æ— æ•°æ®å¯å¯¼å‡º")

        with col4:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤", key="clear_data", help="æ¸…é™¤æ‰€æœ‰åé¦ˆæ•°æ®"):
                if st.session_state.get('confirm_clear', False):
                    # æ‰§è¡Œæ¸…é™¤
                    st.session_state.feedback_data = []
                    st.session_state.interaction_feedback = {}
                    if os.path.exists(feedback_system.data_file):  # âœ… ä½¿ç”¨ data_file
                        os.remove(feedback_system.data_file)
                    st.session_state.confirm_clear = False
                    st.success("ğŸ—‘ï¸ æ•°æ®å·²æ¸…é™¤")
                    st.rerun()
                else:
                    # éœ€è¦ç¡®è®¤
                    st.session_state.confirm_clear = True
                    st.warning("âš ï¸ å†æ¬¡ç‚¹å‡»ç¡®è®¤æ¸…é™¤")

        # æ˜¾ç¤ºA/Bæµ‹è¯•ç»„
        st.divider()
        if st.checkbox("æ˜¾ç¤ºA/Bæµ‹è¯•ä¿¡æ¯"):
            test_group = prompt_manager.ab_test_prompt_optimization()
            st.info(f"å½“å‰ä½¿ç”¨æç¤ºè¯æ¨¡æ¿: {test_group}")
    with st.sidebar.expander("ğŸ§ª åé¦ˆç³»ç»Ÿæµ‹è¯•", expanded=False):
        # ğŸ”¥ æ·»åŠ å®é™…çš„åé¦ˆè¡¨å•
        st.write("### ğŸ“ æµ‹è¯•åé¦ˆè¡¨å•")

        # è¯„åˆ†æ»‘å—
        col1, col2 = st.columns(2)
        with col1:
            accuracy = st.slider("å‡†ç¡®æ€§", 1, 5, 3, key="test_accuracy_rating")
            clarity = st.slider("æ¸…æ™°åº¦", 1, 5, 3, key="test_clarity_rating")

        with col2:
            helpfulness = st.slider(
                "æœ‰ç”¨æ€§", 1, 5, 3, key="test_helpfulness_rating")
            relevance = st.slider("ç›¸å…³æ€§", 1, 5, 3, key="test_relevance_rating")

        # è¯„è®ºæ¡†
        test_comment = st.text_area(
            "æµ‹è¯•è¯„è®º", key="test_user_comment", placeholder="è¾“å…¥æµ‹è¯•è¯„è®º...")

        # æäº¤æŒ‰é’®
        if st.button("æäº¤æµ‹è¯•åé¦ˆ"):
            # æ”¶é›†æ•°æ®
            test_feedback_data = {
                'ratings': {
                    'accuracy': accuracy,
                    'helpfulness': helpfulness,
                    'clarity': clarity,
                    'relevance': relevance
                },
                'comment': test_comment.strip() if test_comment else ""
            }

            # ç”Ÿæˆå”¯ä¸€ID
            import time
            interaction_id = f"test_feedback_{int(time.time() * 1000)}"

            # æäº¤åé¦ˆ
            success = feedback_system.submit_feedback(
                interaction_id, test_feedback_data)

            if success:
                st.success("âœ… æµ‹è¯•åé¦ˆæäº¤æˆåŠŸï¼")
            else:
                st.error("âŒ æµ‹è¯•åé¦ˆæäº¤å¤±è´¥ï¼")

        if st.button("ğŸ“ æ£€æŸ¥æ•°æ®æ–‡ä»¶"):
            if os.path.exists(feedback_system.data_file):
                file_size = os.path.getsize(feedback_system.data_file)
                st.success(f"âœ… æ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {file_size} bytes")

                with open(feedback_system.data_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if content.strip():
                        data = json.loads(content)
                        st.info(f"ğŸ“Š åŒ…å« {len(data)} æ¡è®°å½•")
                    else:
                        st.warning("ğŸ“­ æ–‡ä»¶ä¸ºç©º")
            else:
                st.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {feedback_system.data_file}")

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "messages" not in st.session_state:
        st.session_state.messages = []

    if "code_output" not in st.session_state:
        st.session_state.code_output = None

    # æ ¹æ®é€‰æ‹©çš„åŠŸèƒ½è°ƒç”¨ç›¸åº”çš„å¤„ç†å‡½æ•°
    if app_mode == "èŠå¤©åŠ©æ‰‹":
        handle_chat_assistant(model, temperature, max_tokens)
    elif app_mode == "è®ºæ–‡åˆ†æ":
        handle_paper_analysis(model, max_tokens)
    elif app_mode == "æ•™è‚²å†…å®¹ç”Ÿæˆ":
        handle_education_content(model, max_tokens)
    elif app_mode == "å·¥å…·é›†æˆ":
        handle_tool_integration()

    # é¡µè„šä¿¡æ¯
    st.markdown("---")

    # æ˜¾ç¤ºåé¦ˆåˆ†æ
    if st.session_state.get("feedback_data"):
        analysis = feedback_system.analyze_feedback_trends()
        if analysis and analysis.get("improvement_areas"):
            with st.expander("ğŸ’¡ ç³»ç»Ÿä¼˜åŒ–å»ºè®®", expanded=False):
                st.markdown("### ğŸ“ˆ åé¦ˆåˆ†æ")
                st.metric("æ€»åé¦ˆæ•°", analysis["total_feedback"])
                st.metric("å¹³å‡è¯„åˆ†", f"{analysis['avg_rating']:.1f}/5.0")
                st.metric("ä½è¯„åˆ†æ•°é‡", analysis["low_rating_count"])

                if analysis["improvement_areas"]:
                    st.markdown("### ğŸ¯ æ”¹è¿›å»ºè®®")
                    for suggestion in analysis["improvement_areas"]:
                        st.markdown(f"- {suggestion}")

                # å¯¼å‡ºåé¦ˆæ•°æ®
                if st.button("ğŸ“¥ å¯¼å‡ºåé¦ˆæ•°æ®"):
                    csv_data = feedback_system.export_feedback_data()
                    if csv_data:
                        st.download_button(
                            label="ä¸‹è½½CSVæ–‡ä»¶",
                            data=csv_data,
                            file_name=f"feedback_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
                        st.success("âœ… åé¦ˆæ•°æ®å·²å‡†å¤‡å¥½ä¸‹è½½ï¼")

    st.markdown("Â© 2025 Chat-AI | åŸºäºå¤šç§LLMæ¨¡å‹æ„å»º | æ¨¡å—åŒ–æ¶æ„è®¾è®¡")


if __name__ == "__main__":
    main()
